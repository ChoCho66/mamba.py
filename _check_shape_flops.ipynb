{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's shape: torch.Size([2, 5, 1])\n",
      "y's shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "from c66 import pps\n",
    "import torch\n",
    "x = torch.randn(2,5,1)\n",
    "y = torch.randn(3,)\n",
    "pps(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 7\n",
      "L: 286\n",
      "D: 64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mambapy.mamba import Mamba, MambaConfig\n",
    "from torchinfo import summary\n",
    "from c66 import pp\n",
    "\n",
    "# B, L, D = 7, 64, 16\n",
    "B, L, D = 7, 286, 64\n",
    "pp(B,L,D)\n",
    "\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False)\n",
    "model = Mamba(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        ...,\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].mixer.A_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].mixer.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 7\n",
      "L: 286\n",
      "D: 64\n",
      "------------------------------\n",
      "In ResidualBlock\n",
      "x.shape: torch.Size([7, 286, 64])\n",
      "self.norm(x).shape: torch.Size([7, 286, 64])\n",
      "------------------------------\n",
      "------------------------------\n",
      "In MambaBlock\n",
      "B, L, ED, N, dt_rank: 7 286 128 16 4\n",
      "x.shape: torch.Size([7, 286, 128])\n",
      "delta.shape: torch.Size([7, 286, 128])\n",
      "A.shape: torch.Size([128, 16])\n",
      "B.shape: torch.Size([7, 286, 16])\n",
      "C.shape: torch.Size([7, 286, 16])\n",
      "z.shape: torch.Size([7, 286, 128])\n",
      "self.selective_scan\n",
      "最初的X\n",
      "X's shape: torch.Size([7, 128, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-6.6600e-06, -4.9130e-05, -2.5699e-05],\n",
      "        [-2.3167e-05,  7.0279e-05, -1.2622e-05],\n",
      "        [-2.7348e-04, -2.3712e-04,  7.8647e-05]])\n",
      "X.abs().mean(): 0.00018666102550923824\n",
      "B: 7\n",
      "D: 128\n",
      "L: 512\n",
      "N: 16\n",
      "up sweep finish.\n",
      "中間的X\n",
      "Xa's shape: torch.Size([7, 128, 4, 16])\n",
      "X's shape: torch.Size([7, 128, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-6.6600e-06, -4.9130e-05, -2.5699e-05],\n",
      "        [-2.9764e-05,  2.2072e-05, -3.7600e-05],\n",
      "        [-2.7348e-04, -2.3712e-04,  7.8647e-05]])\n",
      "X.abs().mean(): 0.000266633287537843\n",
      "down sweep begin\n",
      "Xa's shape: torch.Size([7, 128, 256, 2, 16])\n",
      "結束的X\n",
      "X's shape: torch.Size([7, 128, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-6.6600e-06, -4.9130e-05, -2.5699e-05],\n",
      "        [-2.9764e-05,  2.2072e-05, -3.7600e-05],\n",
      "        [-3.0299e-04, -2.1543e-04,  4.2022e-05]])\n",
      "X.abs().mean(): 0.0008320470224134624\n",
      "------------------------------\n",
      "x.shape: torch.Size([7, 286, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mambapy.mamba import Mamba, MambaConfig, MambaBlock\n",
    "from torchinfo import summary\n",
    "from c66 import pp\n",
    "\n",
    "# B, L, D = 7, 64, 16\n",
    "B, L, D = 7, 286, 64\n",
    "pp(B,L,D)\n",
    "\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False)\n",
    "model = Mamba(config)\n",
    "# .to(\"cuda\")\n",
    "\n",
    "x = torch.randn(B, L, D)\n",
    "# .to(\"cuda\")\n",
    "y = model(x)\n",
    "\n",
    "assert y.shape == x.shape\n",
    "pp(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64])\n",
      "3\n",
      "tensor([ 8, 16, 24, 32, 40, 48, 56, 64])\n",
      "2\n",
      "tensor([ 4,  8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64])\n",
      "1\n",
      "tensor([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36,\n",
      "        38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64])\n",
      "0\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64])\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6\n",
    "print(torch.arange(1,2**num_steps+1))\n",
    "for k in range(num_steps-3,-1,-1):\n",
    "    print(k)\n",
    "    print(torch.arange(1,2**num_steps+1)[2**k-1:2**num_steps:2**k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaBlock(\n",
      "  (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
      "  (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "  (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
      "  (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].mixer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MambaBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mamba = model.layers[0].mixer\n",
    "from mambapy.mamba import Mamba, MambaConfig, MambaBlock\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False, \n",
    "                     expand_factor=4,\n",
    "                     )\n",
    "model_mamba = MambaBlock(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.2850,  0.1104,  0.4010,  0.0377]],\n",
       "\n",
       "        [[ 0.1681, -0.2200,  0.1277, -0.2068]],\n",
       "\n",
       "        [[ 0.1601, -0.1528,  0.1214,  0.0539]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1568,  0.2847,  0.2409, -0.0708]],\n",
       "\n",
       "        [[-0.3168, -0.3974,  0.3912, -0.2257]],\n",
       "\n",
       "        [[ 0.4370, -0.4213,  0.4236,  0.0247]]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mamba.conv1d.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "In MambaBlock\n",
      "B, L, ED, N, dt_rank: 1 286 256 16 4\n",
      "x.shape: torch.Size([1, 286, 256])\n",
      "delta.shape: torch.Size([1, 286, 256])\n",
      "A.shape: torch.Size([256, 16])\n",
      "B.shape: torch.Size([1, 286, 16])\n",
      "C.shape: torch.Size([1, 286, 16])\n",
      "z.shape: torch.Size([1, 286, 256])\n",
      "self.selective_scan\n",
      "最初的X\n",
      "X's shape: torch.Size([1, 256, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-1.1290e-04,  5.8376e-04,  1.7332e-04],\n",
      "        [-7.2843e-04,  1.2419e-03,  8.3333e-04],\n",
      "        [ 8.0439e-05,  5.5910e-04,  7.8813e-04]], device='cuda:0')\n",
      "X.abs().mean(): 0.00013546888658311218\n",
      "B: 1\n",
      "D: 256\n",
      "L: 512\n",
      "N: 16\n",
      "up sweep finish.\n",
      "中間的X\n",
      "Xa's shape: torch.Size([1, 256, 4, 16])\n",
      "X's shape: torch.Size([1, 256, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-1.1290e-04,  5.8376e-04,  1.7332e-04],\n",
      "        [-8.3808e-04,  1.7925e-03,  9.9209e-04],\n",
      "        [ 8.0439e-05,  5.5910e-04,  7.8813e-04]], device='cuda:0')\n",
      "X.abs().mean(): 0.00024662743089720607\n",
      "down sweep begin\n",
      "Xa's shape: torch.Size([1, 256, 256, 2, 16])\n",
      "結束的X\n",
      "X's shape: torch.Size([1, 256, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-0.0001,  0.0006,  0.0002],\n",
      "        [-0.0008,  0.0018,  0.0010],\n",
      "        [-0.0007,  0.0023,  0.0017]], device='cuda:0')\n",
      "X.abs().mean(): 0.0011010131565853953\n",
      "------------------------------\n",
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "MambaBlock                               [1, 286, 64]              [1, 286, 64]              5,632\n",
      "├─Linear: 1-1                            [1, 286, 64]              [1, 286, 512]             32,768\n",
      "├─Conv1d: 1-2                            [1, 256, 286]             [1, 256, 289]             1,280\n",
      "├─Linear: 1-3                            [1, 286, 256]             [1, 286, 36]              9,216\n",
      "├─Linear: 1-4                            [1, 286, 256]             [1, 286, 64]              16,384\n",
      "===================================================================================================================\n",
      "Total params: 65,280\n",
      "Trainable params: 65,280\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.43\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 1.99\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 2.30\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "(B,L,D) = (1, 286, 64)\n",
    "with torch.no_grad():\n",
    "    summary_str = summary(model_mamba, input_size=[(B,L,D)], depth=5, col_names=(\"input_size\", \"output_size\", \"num_params\"), verbose=0)\n",
    "    print(summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "In MambaBlock\n",
      "B, L, ED, N, dt_rank: 1 286 256 16 4\n",
      "x.shape: torch.Size([1, 286, 256])\n",
      "delta.shape: torch.Size([1, 286, 256])\n",
      "A.shape: torch.Size([256, 16])\n",
      "B.shape: torch.Size([1, 286, 16])\n",
      "C.shape: torch.Size([1, 286, 16])\n",
      "z.shape: torch.Size([1, 286, 256])\n",
      "self.selective_scan\n",
      "最初的X\n",
      "X's shape: torch.Size([1, 256, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-1.9654e-05,  2.5319e-04, -1.8540e-04],\n",
      "        [ 6.6260e-05,  8.9256e-06,  8.0261e-05],\n",
      "        [ 1.3902e-04,  1.3509e-03,  5.0110e-04]], device='cuda:0')\n",
      "X.abs().mean(): 0.00018443376757204533\n",
      "B: 1\n",
      "D: 256\n",
      "L: 512\n",
      "N: 16\n",
      "up sweep finish.\n",
      "中間的X\n",
      "Xa's shape: torch.Size([1, 256, 4, 16])\n",
      "X's shape: torch.Size([1, 256, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-1.9654e-05,  2.5319e-04, -1.8540e-04],\n",
      "        [ 4.7149e-05,  2.4830e-04, -9.0170e-05],\n",
      "        [ 1.3902e-04,  1.3509e-03,  5.0110e-04]], device='cuda:0')\n",
      "X.abs().mean(): 0.0002665412030182779\n",
      "down sweep begin\n",
      "Xa's shape: torch.Size([1, 256, 256, 2, 16])\n",
      "結束的X\n",
      "X's shape: torch.Size([1, 256, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[-1.9654e-05,  2.5319e-04, -1.8540e-04],\n",
      "        [ 4.7149e-05,  2.4830e-04, -9.0170e-05],\n",
      "        [ 1.8478e-04,  1.5848e-03,  4.1865e-04]], device='cuda:0')\n",
      "X.abs().mean(): 0.0007935006287880242\n",
      "------------------------------\n",
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  65.28 K \n",
      "fwd MACs:                                                               16.99 MMACs\n",
      "fwd FLOPs:                                                              38.35 MFLOPS\n",
      "fwd+bwd MACs:                                                           50.97 MMACs\n",
      "fwd+bwd FLOPs:                                                          115.04 MFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "MambaBlock(\n",
      "  65.28 K = 100% Params, 16.99 MMACs = 100% MACs, 38.35 MFLOPS = 100% FLOPs\n",
      "  (in_proj): Linear(32.77 K = 50.2% Params, 9.37 MMACs = 55.16% MACs, 18.74 MFLOPS = 48.88% FLOPs, in_features=64, out_features=512, bias=False)\n",
      "  (conv1d): Conv1d(1.28 K = 1.96% Params, 295.94 KMACs = 1.74% MACs, 665.86 KFLOPS = 1.74% FLOPs, 256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "  (x_proj): Linear(9.22 K = 14.12% Params, 2.64 MMACs = 15.51% MACs, 5.27 MFLOPS = 13.75% FLOPs, in_features=256, out_features=36, bias=False)\n",
      "  (dt_proj): Linear(1.28 K = 1.96% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=4, out_features=256, bias=True)\n",
      "  (out_proj): Linear(16.38 K = 25.1% Params, 4.69 MMACs = 27.58% MACs, 9.37 MFLOPS = 24.44% FLOPs, in_features=256, out_features=64, bias=False)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total FLOPs: 38.35 MFLOPS\n",
      "Total Params: 65.28 K\n",
      "Total MACs: 16.99 MMACs\n"
     ]
    }
   ],
   "source": [
    "input_x = torch.randn(1,286,64)\n",
    "# input_x = torch.randn(500,286,64)\n",
    "\n",
    "from calflops import calculate_flops\n",
    "with torch.no_grad():\n",
    "        # 使用 calflops 計算 FLOPs，將 args 改為列表\n",
    "        flops, macs, params = calculate_flops(\n",
    "            model=model_mamba,\n",
    "            args=[input_x],  # 使用列表而非元組\n",
    "            print_results=True  # 顯示逐層結果\n",
    "        )\n",
    "        # print(f\"Total FLOPs for {fname}: {flops / 1e9:.3f} GFLOPs\")\n",
    "        # print(f\"Total Params: {params / 1e6:.3f} M\")\n",
    "        # print(f\"Total MACs: {macs / 1e9:.3f} GMACs\")\n",
    "        print(f\"Total FLOPs: {flops}\")\n",
    "        print(f\"Total Params: {params}\")\n",
    "        print(f\"Total MACs: {macs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
