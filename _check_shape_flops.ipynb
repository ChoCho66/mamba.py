{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's shape: torch.Size([2, 5, 1])\n",
      "y's shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "from c66 import pps\n",
    "import torch\n",
    "x = torch.randn(2,5,1)\n",
    "y = torch.randn(3,)\n",
    "pps(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 7\n",
      "L: 286\n",
      "D: 64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mambapy.mamba import Mamba, MambaConfig\n",
    "from torchinfo import summary\n",
    "from c66 import pp\n",
    "\n",
    "# B, L, D = 7, 64, 16\n",
    "B, L, D = 7, 286, 64\n",
    "pp(B,L,D)\n",
    "\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False)\n",
    "model = Mamba(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        ...,\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].mixer.A_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].mixer.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 7\n",
      "L: 286\n",
      "D: 64\n",
      "------------------------------\n",
      "In ResidualBlock\n",
      "x.shape: torch.Size([7, 286, 64])\n",
      "self.norm(x).shape: torch.Size([7, 286, 64])\n",
      "------------------------------\n",
      "------------------------------\n",
      "In MambaBlock\n",
      "B, L, ED, N, dt_rank: 7 286 128 16 4\n",
      "x.shape: torch.Size([7, 286, 128])\n",
      "delta.shape: torch.Size([7, 286, 128])\n",
      "A.shape: torch.Size([128, 16])\n",
      "B.shape: torch.Size([7, 286, 16])\n",
      "C.shape: torch.Size([7, 286, 16])\n",
      "z.shape: torch.Size([7, 286, 128])\n",
      "self.selective_scan\n",
      "最初的X\n",
      "X's shape: torch.Size([7, 128, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[ 4.6876e-05,  6.9070e-06,  2.0421e-05],\n",
      "        [ 2.1344e-05, -3.1894e-06,  1.0125e-04],\n",
      "        [ 6.1279e-06,  1.6529e-05,  3.4905e-05]])\n",
      "X.abs().mean(): 0.0002599538129288703\n",
      "B: 7\n",
      "D: 128\n",
      "L: 512\n",
      "N: 16\n",
      "up sweep finish.\n",
      "中間的X\n",
      "Xa's shape: torch.Size([7, 128, 4, 16])\n",
      "X's shape: torch.Size([7, 128, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[4.6876e-05, 6.9070e-06, 2.0421e-05],\n",
      "        [6.8087e-05, 3.6785e-06, 1.2150e-04],\n",
      "        [6.1279e-06, 1.6529e-05, 3.4905e-05]])\n",
      "X.abs().mean(): 0.00038489262806251645\n",
      "down sweep begin\n",
      "Xa's shape: torch.Size([7, 128, 256, 2, 16])\n",
      "結束的X\n",
      "X's shape: torch.Size([7, 128, 512, 16])\n",
      "X[0, 0, :3, :3]: tensor([[4.6876e-05, 6.9070e-06, 2.0421e-05],\n",
      "        [6.8087e-05, 3.6785e-06, 1.2150e-04],\n",
      "        [7.4021e-05, 2.0186e-05, 1.5537e-04]])\n",
      "X.abs().mean(): 0.0012313983170315623\n",
      "------------------------------\n",
      "x.shape: torch.Size([7, 286, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mambapy.mamba import Mamba, MambaConfig, MambaBlock\n",
    "from torchinfo import summary\n",
    "from c66 import pp\n",
    "\n",
    "# B, L, D = 7, 64, 16\n",
    "B, L, D = 7, 286, 64\n",
    "pp(B,L,D)\n",
    "\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False)\n",
    "model = Mamba(config)\n",
    "# .to(\"cuda\")\n",
    "\n",
    "x = torch.randn(B, L, D)\n",
    "# .to(\"cuda\")\n",
    "y = model(x)\n",
    "\n",
    "assert y.shape == x.shape\n",
    "pp(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64])\n",
      "3\n",
      "tensor([ 8, 16, 24, 32, 40, 48, 56, 64])\n",
      "2\n",
      "tensor([ 4,  8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64])\n",
      "1\n",
      "tensor([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36,\n",
      "        38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64])\n",
      "0\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "        55, 56, 57, 58, 59, 60, 61, 62, 63, 64])\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6\n",
    "print(torch.arange(1,2**num_steps+1))\n",
    "for k in range(num_steps-3,-1,-1):\n",
    "    print(k)\n",
    "    print(torch.arange(1,2**num_steps+1)[2**k-1:2**num_steps:2**k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaBlock(\n",
      "  (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
      "  (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "  (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
      "  (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].mixer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MambaBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mamba = model.layers[0].mixer\n",
    "from mambapy.mamba import Mamba, MambaConfig, MambaBlock\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False, \n",
    "                     expand_factor=4,\n",
    "                     )\n",
    "model_mamba = MambaBlock(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "In MambaBlock\n",
      "B, L, ED, N, dt_rank: 100 286 256 16 4\n",
      "x.shape: torch.Size([100, 286, 256])\n",
      "delta.shape: torch.Size([100, 286, 256])\n",
      "A.shape: torch.Size([256, 16])\n",
      "B.shape: torch.Size([100, 286, 16])\n",
      "C.shape: torch.Size([100, 286, 16])\n",
      "z.shape: torch.Size([100, 286, 256])\n",
      "self.selective_scan\n",
      "-------\n",
      "tensor([ 2.4182e-06,  1.9445e-05, -4.6299e-06], device='cuda:0')\n",
      "B: 100\n",
      "D: 256\n",
      "L: 512\n",
      "N: 16\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 256, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 256, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 128, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 128, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 64, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 64, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 32, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 32, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 16, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 16, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 8, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 8, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 4, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 4, 16])\n",
      "up sweep finish.\n",
      "Xa's shape: torch.Size([100, 256, 4, 16])\n",
      "X's shape: torch.Size([100, 256, 512, 16])\n",
      "down sweep begin\n",
      "Xa's shape: torch.Size([100, 256, 256, 2, 16])\n",
      "X's shape: torch.Size([100, 256, 512, 16])\n",
      "tensor([ 2.4182e-06,  1.9445e-05, -4.6299e-06], device='cuda:0')\n",
      "-------\n",
      "------------------------------\n",
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "MambaBlock                               [100, 286, 64]            [100, 286, 64]            5,632\n",
      "├─Linear: 1-1                            [100, 286, 64]            [100, 286, 512]           32,768\n",
      "├─Conv1d: 1-2                            [100, 256, 286]           [100, 256, 289]           1,280\n",
      "├─Linear: 1-3                            [100, 286, 256]           [100, 286, 36]            9,216\n",
      "├─Linear: 1-4                            [100, 286, 256]           [100, 286, 64]            16,384\n",
      "===================================================================================================================\n",
      "Total params: 65,280\n",
      "Trainable params: 65,280\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 42.83\n",
      "===================================================================================================================\n",
      "Input size (MB): 7.32\n",
      "Forward/backward pass size (MB): 199.21\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 206.77\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "(B,L,D) = (100, 286, 64)\n",
    "with torch.no_grad():\n",
    "    summary_str = summary(model_mamba, input_size=[(B,L,D)], depth=5, col_names=(\"input_size\", \"output_size\", \"num_params\"), verbose=0)\n",
    "    print(summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "In MambaBlock\n",
      "B, L, ED, N, dt_rank: 100 286 256 16 4\n",
      "x.shape: torch.Size([100, 286, 256])\n",
      "delta.shape: torch.Size([100, 286, 256])\n",
      "A.shape: torch.Size([256, 16])\n",
      "B.shape: torch.Size([100, 286, 16])\n",
      "C.shape: torch.Size([100, 286, 16])\n",
      "z.shape: torch.Size([100, 286, 256])\n",
      "self.selective_scan\n",
      "-------\n",
      "tensor([-1.1309e-06, -2.4537e-07,  7.4916e-07], device='cuda:0')\n",
      "B: 100\n",
      "D: 256\n",
      "L: 512\n",
      "N: 16\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 256, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 256, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 128, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 128, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 64, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 64, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 32, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 32, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 16, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 16, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 8, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 8, 16])\n",
      "把 Aa, Xa 分成兩塊\n",
      "Xa's shape: torch.Size([100, 256, 4, 2, 16])\n",
      "把 Aa[:, :, :, 1], Xa[:, :, :, 1] 當成新的 Aa, Xa\n",
      "Xa's shape: torch.Size([100, 256, 4, 16])\n",
      "up sweep finish.\n",
      "Xa's shape: torch.Size([100, 256, 4, 16])\n",
      "X's shape: torch.Size([100, 256, 512, 16])\n",
      "down sweep begin\n",
      "Xa's shape: torch.Size([100, 256, 256, 2, 16])\n",
      "X's shape: torch.Size([100, 256, 512, 16])\n",
      "tensor([-1.1309e-06, -2.4537e-07,  7.4916e-07], device='cuda:0')\n",
      "-------\n",
      "------------------------------\n",
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  65.28 K \n",
      "fwd MACs:                                                               1.7 GMACs\n",
      "fwd FLOPs:                                                              3.83 GFLOPS\n",
      "fwd+bwd MACs:                                                           5.1 GMACs\n",
      "fwd+bwd FLOPs:                                                          11.5 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "MambaBlock(\n",
      "  65.28 K = 100% Params, 1.7 GMACs = 100% MACs, 3.83 GFLOPS = 100% FLOPs\n",
      "  (in_proj): Linear(32.77 K = 50.2% Params, 937.16 MMACs = 55.16% MACs, 1.87 GFLOPS = 48.88% FLOPs, in_features=64, out_features=512, bias=False)\n",
      "  (conv1d): Conv1d(1.28 K = 1.96% Params, 29.59 MMACs = 1.74% MACs, 66.59 MFLOPS = 1.74% FLOPs, 256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "  (x_proj): Linear(9.22 K = 14.12% Params, 263.58 MMACs = 15.51% MACs, 527.16 MFLOPS = 13.75% FLOPs, in_features=256, out_features=36, bias=False)\n",
      "  (dt_proj): Linear(1.28 K = 1.96% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=4, out_features=256, bias=True)\n",
      "  (out_proj): Linear(16.38 K = 25.1% Params, 468.58 MMACs = 27.58% MACs, 937.16 MFLOPS = 24.44% FLOPs, in_features=256, out_features=64, bias=False)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total FLOPs: 3.83 GFLOPS\n",
      "Total Params: 65.28 K\n",
      "Total MACs: 1.7 GMACs\n"
     ]
    }
   ],
   "source": [
    "input_x = torch.randn(100,286,64)\n",
    "# input_x = torch.randn(500,286,64)\n",
    "\n",
    "from calflops import calculate_flops\n",
    "with torch.no_grad():\n",
    "        # 使用 calflops 計算 FLOPs，將 args 改為列表\n",
    "        flops, macs, params = calculate_flops(\n",
    "            model=model_mamba,\n",
    "            args=[input_x],  # 使用列表而非元組\n",
    "            print_results=True  # 顯示逐層結果\n",
    "        )\n",
    "        # print(f\"Total FLOPs for {fname}: {flops / 1e9:.3f} GFLOPs\")\n",
    "        # print(f\"Total Params: {params / 1e6:.3f} M\")\n",
    "        # print(f\"Total MACs: {macs / 1e9:.3f} GMACs\")\n",
    "        print(f\"Total FLOPs: {flops}\")\n",
    "        print(f\"Total Params: {params}\")\n",
    "        print(f\"Total MACs: {macs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
