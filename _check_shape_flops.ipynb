{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 7\n",
      "L: 286\n",
      "D: 64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mambapy.mamba import Mamba, MambaConfig\n",
    "from torchinfo import summary\n",
    "from c66 import pp\n",
    "\n",
    "# B, L, D = 7, 64, 16\n",
    "B, L, D = 7, 286, 64\n",
    "pp(B,L,D)\n",
    "\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False)\n",
    "model = Mamba(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        ...,\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726],\n",
       "        [0.0000, 0.6931, 1.0986,  ..., 2.6391, 2.7081, 2.7726]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].mixer.A_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].mixer.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: 7\n",
      "L: 286\n",
      "D: 64\n",
      "------------------------------\n",
      "In ResidualBlock\n",
      "x.shape: torch.Size([7, 286, 64])\n",
      "self.norm(x).shape: torch.Size([7, 286, 64])\n",
      "------------------------------\n",
      "------------------------------\n",
      "In MambaBlock\n",
      "torch.Size([7, 128, 286])\n",
      "torch.Size([7, 128, 286])\n",
      "B, L, ED, N, dt_rank: 7 286 128 16 4\n",
      "x.shape: torch.Size([7, 286, 128])\n",
      "delta.shape: torch.Size([7, 286, 128])\n",
      "A.shape: torch.Size([128, 16])\n",
      "B.shape: torch.Size([7, 286, 16])\n",
      "C.shape: torch.Size([7, 286, 16])\n",
      "z.shape: torch.Size([7, 286, 128])\n",
      "self.selective_scan\n",
      "------------------------------\n",
      "x.shape: torch.Size([7, 286, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mambapy.mamba import Mamba, MambaConfig\n",
    "from torchinfo import summary\n",
    "from c66 import pp\n",
    "\n",
    "# B, L, D = 7, 64, 16\n",
    "B, L, D = 7, 286, 64\n",
    "pp(B,L,D)\n",
    "\n",
    "config = MambaConfig(d_model=D, n_layers=1, use_cuda=False)\n",
    "model = Mamba(config)\n",
    "# .to(\"cuda\")\n",
    "\n",
    "x = torch.randn(B, L, D)\n",
    "# .to(\"cuda\")\n",
    "y = model(x)\n",
    "\n",
    "assert y.shape == x.shape\n",
    "pp(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba(\n",
      "  (layers): ModuleList(\n",
      "    (0): ResidualBlock(\n",
      "      (mixer): MambaBlock(\n",
      "        (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
      "        (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "        (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
      "        (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
      "        (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
      "      )\n",
      "      (norm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MambaBlock(\n",
      "  (in_proj): Linear(in_features=64, out_features=256, bias=False)\n",
      "  (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "  (x_proj): Linear(in_features=128, out_features=36, bias=False)\n",
      "  (dt_proj): Linear(in_features=4, out_features=128, bias=True)\n",
      "  (out_proj): Linear(in_features=128, out_features=64, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].mixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mamba = model.layers[0].mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "In MambaBlock\n",
      "torch.Size([7, 128, 286])\n",
      "torch.Size([7, 128, 286])\n",
      "B, L, ED, N, dt_rank: 7 286 128 16 4\n",
      "x.shape: torch.Size([7, 286, 128])\n",
      "delta.shape: torch.Size([7, 286, 128])\n",
      "A.shape: torch.Size([128, 16])\n",
      "B.shape: torch.Size([7, 286, 16])\n",
      "C.shape: torch.Size([7, 286, 16])\n",
      "z.shape: torch.Size([7, 286, 128])\n",
      "self.selective_scan\n",
      "------------------------------\n",
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "MambaBlock                               [7, 286, 64]              [7, 286, 64]              2,816\n",
      "├─Linear: 1-1                            [7, 286, 64]              [7, 286, 256]             16,384\n",
      "├─Conv1d: 1-2                            [7, 128, 286]             [7, 128, 289]             640\n",
      "├─Linear: 1-3                            [7, 286, 128]             [7, 286, 36]              4,608\n",
      "├─Linear: 1-4                            [7, 286, 128]             [7, 286, 64]              8,192\n",
      "===================================================================================================================\n",
      "Total params: 32,640\n",
      "Trainable params: 32,640\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 1.50\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.51\n",
      "Forward/backward pass size (MB): 7.77\n",
      "Params size (MB): 0.12\n",
      "Estimated Total Size (MB): 8.41\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "(B,L,D) = (7,286,64)\n",
    "with torch.no_grad():\n",
    "    summary_str = summary(model_mamba, input_size=[(B,L,D)], depth=5, col_names=(\"input_size\", \"output_size\", \"num_params\"), verbose=0)\n",
    "    print(summary_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "In MambaBlock\n",
      "torch.Size([100, 128, 286])\n",
      "torch.Size([100, 128, 286])\n",
      "B, L, ED, N, dt_rank: 100 286 128 16 4\n",
      "x.shape: torch.Size([100, 286, 128])\n",
      "delta.shape: torch.Size([100, 286, 128])\n",
      "A.shape: torch.Size([128, 16])\n",
      "B.shape: torch.Size([100, 286, 16])\n",
      "C.shape: torch.Size([100, 286, 16])\n",
      "z.shape: torch.Size([100, 286, 128])\n",
      "self.selective_scan\n",
      "------------------------------\n",
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  32.64 K \n",
      "fwd MACs:                                                               849.46 MMACs\n",
      "fwd FLOPs:                                                              1.92 GFLOPS\n",
      "fwd+bwd MACs:                                                           2.55 GMACs\n",
      "fwd+bwd FLOPs:                                                          5.75 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "MambaBlock(\n",
      "  32.64 K = 100% Params, 849.46 MMACs = 100% MACs, 1.92 GFLOPS = 100% FLOPs\n",
      "  (in_proj): Linear(16.38 K = 50.2% Params, 468.58 MMACs = 55.16% MACs, 937.16 MFLOPS = 48.88% FLOPs, in_features=64, out_features=256, bias=False)\n",
      "  (conv1d): Conv1d(640 = 1.96% Params, 14.8 MMACs = 1.74% MACs, 33.29 MFLOPS = 1.74% FLOPs, 128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
      "  (x_proj): Linear(4.61 K = 14.12% Params, 131.79 MMACs = 15.51% MACs, 263.58 MFLOPS = 13.75% FLOPs, in_features=128, out_features=36, bias=False)\n",
      "  (dt_proj): Linear(640 = 1.96% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=4, out_features=128, bias=True)\n",
      "  (out_proj): Linear(8.19 K = 25.1% Params, 234.29 MMACs = 27.58% MACs, 468.58 MFLOPS = 24.44% FLOPs, in_features=128, out_features=64, bias=False)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total FLOPs: 1.92 GFLOPS\n",
      "Total Params: 32.64 K\n",
      "Total MACs: 849.46 MMACs\n"
     ]
    }
   ],
   "source": [
    "input_x = torch.randn(100,286,64)\n",
    "# input_x = torch.randn(500,286,64)\n",
    "\n",
    "from calflops import calculate_flops\n",
    "with torch.no_grad():\n",
    "        # 使用 calflops 計算 FLOPs，將 args 改為列表\n",
    "        flops, macs, params = calculate_flops(\n",
    "            model=model_mamba,\n",
    "            args=[input_x],  # 使用列表而非元組\n",
    "            print_results=True  # 顯示逐層結果\n",
    "        )\n",
    "        # print(f\"Total FLOPs for {fname}: {flops / 1e9:.3f} GFLOPs\")\n",
    "        # print(f\"Total Params: {params / 1e6:.3f} M\")\n",
    "        # print(f\"Total MACs: {macs / 1e9:.3f} GMACs\")\n",
    "        print(f\"Total FLOPs: {flops}\")\n",
    "        print(f\"Total Params: {params}\")\n",
    "        print(f\"Total MACs: {macs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
